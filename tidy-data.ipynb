{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook uses simple unit tests to check the correctness of your code.\n",
    "\n",
    "Make sure the tests for each cell pass before continuing to the next because some tests rely on state created in previous cells. \n",
    "\n",
    "If you find it difficult to debug a particular step try to **restart the kernel** (in the menu bar, select Kernel$\\rightarrow$Restart & Run All), to clear any previously stored data.\n",
    "\n",
    "Make sure you fill in all places that say `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "\n",
    "You must delete `raise NotImplementedError()` when you implement each solution.\n",
    "\n",
    "Goldsmiths students only: You must use the template provided to be graded. Do not rename the file and use only use relative filenames otherwise the autograder will fail to grade your work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f47cbaa06fe4ff28e450a780e6d450",
     "grade": false,
     "grade_id": "cell-208f2ff137b1f9e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c462abcb2dc340c6167479a5673ba1ac",
     "grade": false,
     "grade_id": "cell-814e3cfee49e09e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For unit testing answers.\n",
    "from unittest.mock import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b91f7ddd4d794c4d19772df748ac3cf",
     "grade": false,
     "grade_id": "cell-5a2a232dd36b584a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## UK CO2 emissions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19524fc44cc0ab80004612d2ba9f072b",
     "grade": false,
     "grade_id": "cell-db939546d375ecc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Open the file 'carbon-emissions-borough.xls' in a spreadsheet program and take a look at the information in the 'Metadata' sheet and the data in the 'TOTAL' sheet. \n",
    "\n",
    "Looking at the 'TOTAL' sheet data ask yourself:\n",
    "- how many data variables are there?\n",
    "- which variables could be useful index variables?\n",
    "- which variables contain raw data values and which contain aggregate statistics?\n",
    "- are the units of measurement consistant for this table? (hint: look what happens at row 38).\n",
    "\n",
    "Although the layout of this data may be relatively intuitiate from a human perspective, it is very much *not* tidy from a data processing point of view.\n",
    "\n",
    "We are going to convert some of this data step-by-step into tidy data.\n",
    "\n",
    "First, read the entire sheet named 'TOTAL' from the file 'carbon-emissions-borough.xls' into a pandas DataFrame and assign it to the variable `df`.\n",
    "\n",
    "Once you have implemented this step remove the `raise NotImplementedError()` line. \n",
    "\n",
    "Run the cell check the output corresponds to what you see in the Excel sheet.\n",
    "\n",
    "Then test your answer by running the unit tests in the following cell.\n",
    "\n",
    "- hint: look up the documentation for `pandas.read_excel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59b468007f9aa4a6477452b0e508d50f",
     "grade": false,
     "grade_id": "read-raw-sheet",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df = ...\n",
    "\n",
    "# Show both the head and tail of the dataset.\n",
    "df.head().append(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ee9e0907f73fb853fc35eab31e52376",
     "grade": true,
     "grade_id": "read-raw-sheet-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Check we have created a DataFrame.\n",
    "assert type(df) == pd.DataFrame\n",
    "# Basic sanity check that we are loading the correct data.\n",
    "assert df.ndim == 2\n",
    "assert df.shape == (53, 72)\n",
    "assert df.iloc[0, 0] == 'Code'\n",
    "assert df.iloc[-1, 1] == 'United Kingdom'\n",
    "assert df.iloc[0:, 2].sum().round() == 696384.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f34a5b98cd4dffe66fcb530d94a6277d",
     "grade": false,
     "grade_id": "cell-e8b62b4ded0298a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Hopefully loading the entire sheet into a DataFrame was relatively straightforward. But this is not really the best way to start analysing this data because the structure is very untidy.\n",
    "\n",
    "Let's assume for now we are interested only in data concerning *Industry and Commercial* carbon emissions in the most recent year in this dataset: 2014.\n",
    "\n",
    "Copy and paste the previous cell and now add the `usecols` parameter to read in the 'TOTAL' data again but selecting only three columns corresponding to:\n",
    "1. *Code* values\n",
    "2. *Name* values\n",
    "3. 2014 emission values for *Industry and Commercial*.\n",
    "\n",
    "For now don't worry about filtering rows, just read in all available rows.\n",
    "\n",
    "Again assign the new DataFrame to the variable `df`.\n",
    "\n",
    "- hint: lookup the `pd.read_excel()` `usecols` parameter. You can specify columns using Excel column labels ('A', 'B' etc.) or index numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c391490f46d947878174957a3cb1970",
     "grade": false,
     "grade_id": "read-subset-1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df = ...\n",
    "\n",
    "# Show both the head and tail of the dataset.\n",
    "df.head().append(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90bdfec9b8bbf7a58b3b9144c1391337",
     "grade": true,
     "grade_id": "read-subset-1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Check we have created a DataFrame.\n",
    "assert type(df) == pd.DataFrame\n",
    "# Basic sanity check that we are loading the correct data.\n",
    "assert df.ndim == 2\n",
    "assert df.shape == (53, 3)\n",
    "assert df.iloc[0, 0] == 'Code'\n",
    "assert df.iloc[-1, 1] == 'United Kingdom'\n",
    "assert df.iloc[0:, 2].sum().round() == 499978.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3bf8917f5698ff5c4067cbb67c4fb4a",
     "grade": false,
     "grade_id": "cell-c455317a66f894c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next let's try and sort out our column headers.\n",
    "\n",
    "Copy and paste the previous cell and now add the `skiprows` parameter to read in the 'MYE' data again but skipping the unnecessary rows at the top of the spreadsheet.\n",
    "\n",
    "By default pandas uses the first row in the Excel file as the column names for our DataFrame. This isn't very useful for this spreadsheet because the first row is either empty or contains a label indicating that a group of columns correspond to a single variable measured over time.\n",
    "\n",
    "The simplest thing we can do here is just skip the first row (which is row `0` in pandas). Also skip the empty third row  (row `2` in pandas).\n",
    "\n",
    "- hint: look up the `pd.read_excel()` `skiprows` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0176bfec616852956fd734b2089a112e",
     "grade": false,
     "grade_id": "read-subset-2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df = ...\n",
    "\n",
    "# Show both the head and tail of the dataset.\n",
    "df.head().append(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf3e20424fb68c5ff04115e1eb7e013c",
     "grade": true,
     "grade_id": "read-subset-2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Check we have created a DataFrame.\n",
    "assert type(df) == pd.DataFrame\n",
    "# Basic sanity check that we are loading the correct data.\n",
    "assert df.ndim == 2\n",
    "assert df.shape == (51, 3)\n",
    "assert df.iloc[0, 0] == 'E09000001'\n",
    "assert df.iloc[-1, 1] == 'United Kingdom'\n",
    "assert df.iloc[0:, 2].sum().round() == 497964.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19e68ff993b5d3c2a36d135f53f0b4f4",
     "grade": false,
     "grade_id": "cell-14e44edb0130766d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is beginning to look reasonable, now we can deal with the rows.\n",
    "\n",
    "Thinking about tidy data rule 3:\n",
    "\n",
    "> Each type of observational unit forms a table\n",
    "\n",
    "we have a problem in that different observational units are used in this spreadsheet.\n",
    "\n",
    "- rows 4-36: London borough\n",
    "- rows 38-46: UK regions\n",
    "- rows 48-52: UK nations\n",
    "- row 53: UK\n",
    "\n",
    "So let's focus on London. Copy and paste the previous cell and add a `nrows` parameter to create a new DataFrame which contains only the rows corresponding to London boroughs.\n",
    "\n",
    "- hint: look up the `pd.read_excel()` `nrows` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97280c7ddc3d515dd7750160a5d44272",
     "grade": false,
     "grade_id": "read-subset-3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df = ...\n",
    "\n",
    "# Show both the head and tail of the dataset.\n",
    "df.head().append(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33b563d6f62d84bded65bc6fc6aac345",
     "grade": true,
     "grade_id": "read-subset-3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Check we have created a DataFrame.\n",
    "assert type(df) == pd.DataFrame\n",
    "# Basic sanity check that we are loading the correct data.\n",
    "assert df.ndim == 2\n",
    "assert df.shape == (33, 3)\n",
    "assert df.iloc[0, 0] == 'E09000001'\n",
    "assert df.iloc[-1, 1] == 'Westminster'\n",
    "assert df.iloc[0:, 2].sum().round() == 15307.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5d8c1139017f8580dfde3c9628510f5",
     "grade": false,
     "grade_id": "cell-7ce8a1e600f4f529",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have a consistant observational unit, which variable should we use for our index?\n",
    "\n",
    "`Code` looks promising as it seems to be a unique identifier with a consistant structure. The downside being that the codes are not very human readible.\n",
    "\n",
    "`Name` would be a more convienent choice, but is it suitable as a unique identifier?\n",
    "\n",
    "With such a small dataset we could check this manually, but let's check it programatically by counting the number of duplicated values in the `Name` column.\n",
    "\n",
    "For the purpose of unit-testing we need to write our code inside another function called `test_duplicates`. In your own analysis notebooks it wouldn't strictly be necessary to do this, but writing functions to abstract certain tasks can have benefits such as making your code easier to understand and reducing copy-and-paste between code blocks.\n",
    "\n",
    "- hint: the answer is zero, but prove this using the pandas `Series.duplicated` and `Series.sum` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2d4d1a4202a219c700d1c85329a01cc",
     "grade": false,
     "grade_id": "name-duplicates",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_duplicates():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "# Call the test_duplicates function. \n",
    "# Should return the number of duplicated values in the 'Name' column (zero in this case).\n",
    "test_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e48c12eaf5397b7c8fea4306d7a9ec73",
     "grade": true,
     "grade_id": "name-duplicates-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with patch('pandas.Series.duplicated') as mock_duplicated:\n",
    "    test_duplicates()\n",
    "mock_duplicated.assert_called_once_with()\n",
    "\n",
    "with patch('pandas.Series.sum') as mock_sum:\n",
    "    test_duplicates()\n",
    "mock_sum.assert_called_once_with()\n",
    "\n",
    "assert test_duplicates() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can be sure that the `Name` column can be used as a unique identifier we can assign it as the index.\n",
    "\n",
    "There is also no need to read the `Code` variable any more.\n",
    "\n",
    "So create a new DataFrame where:\n",
    "- `Name` is assigned as the index\n",
    "- the only variable is the 2014 emission values for *Industry and Commercial*\n",
    "- rows correspond only to London boroughs.\n",
    "\n",
    "\n",
    "- hint: lookup the `pd.read_excel()` `index_col` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9191acca22bd6cd17f17db1dc116226",
     "grade": false,
     "grade_id": "read-subset-4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df = ...\n",
    "\n",
    "# Show both the head and tail of the dataset.\n",
    "df.head().append(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9278a8da71e0e6d75c69544eeb2b1ed2",
     "grade": true,
     "grade_id": "read-subset-4-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Check we have created a DataFrame.\n",
    "assert type(df) == pd.DataFrame\n",
    "# Basic sanity check that we are loading the correct data.\n",
    "assert df.ndim == 2\n",
    "assert df.shape == (33, 1)\n",
    "assert df.index[0] == 'City of London'\n",
    "assert df.iloc[0, 0].round(2) == 964.60\n",
    "assert df.iloc[-1, 0].round(2) == 1844.33\n",
    "assert df.iloc[0:, 0].sum().round(2) == 15306.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame the same as previously, but now with the following columns.\n",
    "\n",
    "- 2014 emission values for *Industry and Commercial*\n",
    "- 2014 emission values for *Domestic*\n",
    "- 2014 emission values for *Transport*\n",
    "- 2014 emission values for *N. LULUCF Net Emissions* (Land use, land-use change, and forestry)\n",
    "\n",
    "Use the same *Names* column as the index (London borough names).\n",
    "\n",
    "Provide a `names` argument to `read_excel` with the following value.\n",
    "\n",
    "`['borough', 'industry', 'domestic', 'transport', 'lulucf']`\n",
    "\n",
    "- hint: lookup the `pd.read_excel()` `names` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78a28f9ce827382685fb5b8f1b5a656f",
     "grade": false,
     "grade_id": "read-subset-5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df = ...\n",
    "\n",
    "# Show both the head and tail of the dataset.\n",
    "df.head().append(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a458c20210f9d8ae585c532dd2903f04",
     "grade": true,
     "grade_id": "read-subset-5-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Check we have created a DataFrame.\n",
    "assert type(df) == pd.DataFrame\n",
    "# Basic sanity check that we are loading the correct data.\n",
    "assert df.ndim == 2\n",
    "assert df.shape == (33, 4)\n",
    "assert df.index[0] == 'City of London'\n",
    "assert df.index.name == 'borough'\n",
    "assert list(df.columns) == ['industry', 'domestic', 'transport', 'lulucf']\n",
    "assert df.loc[:, 'industry'].sum().round(2) == 15306.93\n",
    "assert df.loc[:, 'domestic'].sum().round(2) == 12556.89\n",
    "assert df.loc[:, 'transport'].sum().round(2) == 7927.57\n",
    "assert df.loc[:, 'lulucf'].sum().round(2) == 26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the DataFrame info.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dtypes for all of our variabes are float64, which is reasonable.\n",
    "\n",
    "However, the index is currently dtype `object`, so we could improve on this slightly by telling pandas that this is a categorical index (there is only a finite list of London boroughs, no more and no less).\n",
    "\n",
    "Using the same `df` variable, convert the index to a categorical index.\n",
    "\n",
    "- hint: lookup `pd.Index.astype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "055dc6936d2ae3717b444839fedcadd1",
     "grade": false,
     "grade_id": "index-dtype",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# df.index = ...\n",
    "\n",
    "df.index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c93a174f114b663c3a1cdb184f4c3192",
     "grade": true,
     "grade_id": "index-dtype-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(df.index.dtype) == pd.CategoricalDtype\n",
    "assert list(df.index.categories) == [\n",
    "    'Barking and Dagenham', 'Barnet', 'Bexley', 'Brent',\n",
    "    'Bromley', 'Camden', 'City of London', 'Croydon', 'Ealing',\n",
    "    'Enfield', 'Greenwich', 'Hackney', 'Hammersmith and Fulham',\n",
    "    'Haringey', 'Harrow', 'Havering', 'Hillingdon', 'Hounslow',\n",
    "    'Islington', 'Kensington and Chelsea',\n",
    "    'Kingston upon Thames', 'Lambeth', 'Lewisham', 'Merton',\n",
    "    'Newham', 'Redbridge', 'Richmond upon Thames', 'Southwark',\n",
    "    'Sutton', 'Tower Hamlets', 'Waltham Forest', 'Wandsworth',\n",
    "    'Westminster'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame is almost tidy!\n",
    "\n",
    "Excpet that the columns `industry`, `domestic`, `transport`, `lulucf` are actually the measure of the same variable: Kilotonnes of Carbon Dioxide (kt CO2), so should be in a single column. A second indicator variable needs to be created specifying the sector the measurement corresponds to.\n",
    "\n",
    "This transformation can be achieved using the `pd.DataFrame.melt` method. Create a new melted DataFrame inside the `apply_melt` function, which should return the tidy DataFrame. Assign the tidy DataFrame to the variable `df_2014`.\n",
    "\n",
    "- name the indicator variable `sector`\n",
    "- name the value variable `co2`\n",
    "- ensure the index is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14e3cd6ca047d08f1f13dee262db8d19",
     "grade": false,
     "grade_id": "melt",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You wouldn't necessarily create a function to perform this melt operation\n",
    "# in a Notebook, but it's necessary for unit testing!\n",
    "\n",
    "def apply_melt():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return ...\n",
    "\n",
    "df_2014 = apply_melt()\n",
    "\n",
    "df_2014.head().append(df_2014.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c1a4275b48d994fedf1e34c5ba99372",
     "grade": true,
     "grade_id": "melt-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Check we have created a DataFrame.\n",
    "assert type(df_2014) == pd.DataFrame\n",
    "# Basic sanity check that we have processed the data correctly.\n",
    "assert df_2014.ndim == 2\n",
    "assert df_2014.shape == (132, 2)\n",
    "assert df_2014.index.name == 'borough'\n",
    "assert type(df_2014.index.dtype) == pd.CategoricalDtype\n",
    "assert list(df_2014.columns) == ['sector', 'co2']\n",
    "assert list(df_2014['sector'].unique() == ['industry', 'domestic', 'transport', 'lulucf'])\n",
    "assert df_2014['co2'].sum().round(2) == 35817.39\n",
    "# Test melt was actually used!\n",
    "with patch('pandas.DataFrame.melt') as mock_melt:\n",
    "    apply_melt()\n",
    "mock_melt.assert_called_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple visualisation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_2014.groupby('sector').sum().sort_values(by='co2').plot.barh(legend=False)\n",
    "ax.set_xlabel('kt CO$_2$')\n",
    "ax.set_title('London 2014: Carbon dioxide emissions per sector')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_2014.boxplot(by='sector')\n",
    "ax.set_xlabel('sector')\n",
    "ax.set_ylabel('kt CO$_2$')\n",
    "ax.set_title('London 2014: Carbon dioxide emissions per sector')\n",
    "ax.figure.suptitle(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_2014.groupby('borough').sum().sort_values(by='co2').plot.barh(legend=False, figsize=(6, 7))\n",
    "ax.set_xlabel('kt CO$_2$')\n",
    "ax.set_title('London 2014: Carbon dioxide emissions per borough')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
